---
---

@string{aps = {American Physical Society,}}

# example article
@comment{
@article{PhysRev.47.777,
  abbr={PhysRev},
  title={Can Quantum-Mechanical Description of Physical Reality Be Considered Complete?},
  author={Einstein*†, A. and Podolsky*, B. and Rosen*, N.},
  abstract={In a complete theory there is an element corresponding to each element of reality. A sufficient condition for the reality of a physical quantity is the possibility of predicting it with certainty, without disturbing the system. In quantum mechanics in the case of two physical quantities described by non-commuting operators, the knowledge of one precludes the knowledge of the other. Then either (1) the description of reality given by the wave function in quantum mechanics is not complete or (2) these two quantities cannot have simultaneous reality. Consideration of the problem of making predictions concerning a system on the basis of measurements made on another system that had previously interacted with it leads to the result that if (1) is false then (2) is also false. One is thus led to conclude that the description of reality as given by a wave function is not complete.},
  journal={Phys. Rev.},
  location={New Jersey},
  volume={47},
  issue={10},
  pages={777--780},
  numpages={0},
  year={1935},
  month={May},
  publisher=aps,
  doi={10.1103/PhysRev.47.777},
  url={http://link.aps.org/doi/10.1103/PhysRev.47.777},
  html={https://journals.aps.org/pr/abstract/10.1103/PhysRev.47.777},
  pdf={example_pdf.pdf},
  altmetric={248277},
  dimensions={true},
  google_scholar_id={qyhmnyLat1gC},
  video={https://www.youtube-nocookie.com/embed/aqz-KE-bpKQ},
  additional_info={. *More Information* can be [found here](https://github.com/alshedivat/al-folio/)},
  annotation={* Example use of superscripts<br>† Albert Einstein},
  selected={true},
  inspirehep_id = {3255}
}
}

@inproceedings{campanini-etal-2024-ihealth,
    title = "i{H}ealth-{C}hile-1 at {RRG}24: In-context Learning and Finetuning of a Large Multimodal Model for Radiology Report Generation",
    author = "Campanini, Diego  and
      Loch, Oscar  and
      Messina, Pablo  and
      Elberg, Rafael  and
      Parra, Denis",
    editor = "Demner-Fushman, Dina  and
      Ananiadou, Sophia  and
      Miwa, Makoto  and
      Roberts, Kirk  and
      Tsujii, Junichi",
    booktitle = "Proceedings of the 23rd Workshop on Biomedical Natural Language Processing, ACL",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.bionlp-1.52/",
    doi = "10.18653/v1/2024.bionlp-1.52",
    pages = "608--613",
    abstract = "This paper presents the approach of the iHealth-Chile-1 team for the shared task of Large-Scale Radiology Report Generation at the BioNLP workshop, inspired by progress in large multimodal models for processing images and text. In this work, we leverage LLaVA, a Visual-Language Model (VLM), composed of a vision-encoder, a vision-language connector or adapter, and a large language model able to process text and visual embeddings. We achieve our best result by enriching the input prompt of LLaVA with the text output of a simpler report generation model. With this enriched-prompt technique, we improve our results in 4 of 5 metrics (BLEU-4, Rouge-L, BertScore and F1-RadGraph,), only doing in-context learning. Moreover, we provide details about different architecture settings, fine-tuning strategies, and dataset configurations.",
    selected={true}
}

@inproceedings{loch-etal-2024-ihealth,
    title = "i{H}ealth-{C}hile-3{\&}2 at {RRG}24: Template Based Report Generation",
    author = "Loch, Oscar  and
      Messina, Pablo  and
      Elberg, Rafael  and
      Campanini, Diego  and
      Soto, {\'A}lvaro  and
      Vidal, Ren{\'e}  and
      Parra, Denis",
    editor = "Demner-Fushman, Dina  and
      Ananiadou, Sophia  and
      Miwa, Makoto  and
      Roberts, Kirk  and
      Tsujii, Junichi",
    booktitle = "Proceedings of the 23rd Workshop on Biomedical Natural Language Processing, ACL",
    month = aug,
    year = "2024",
    address = "Bangkok, Thailand",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2024.bionlp-1.53/",
    doi = "10.18653/v1/2024.bionlp-1.53",
    pages = "614--623",
    abstract = "This paper presents the approaches of the iHealth-Chile-3 and iHealth-Chile-2 teams for the shared task of Large-Scale Radiology Report Generation at the BioNLP workshop. Inspired by prior work on template-based report generation, both teams focused on exploring various template-based strategies, using predictions from multi-label image classifiers as input. Our best approach achieved a modest F1-RadGraph score of 19.42 on the findings hidden test set, ranking 7th on the leaderboard. Notably, we consistently observed a discrepancy between our classification metrics and the F1-CheXbert metric reported on the leaderboard, which always showed lower scores. This suggests that the F1-CheXbert metric may be missing some of the labels mentioned by the templates.",
    selected={true}
}


@article{uchile-homebreakers-2017,
    title = "Uchile homebreakers 2017 team description paper",
    author = "Luz, Martinez  and
      Muñoz, Rodrigo  and
      Olave, Gonzalo  and
      Hernan, Gustavo  and
      Gomez, David and
      Garrido, Leonardo  and
      Campanini, Diego and
      Orellana, Pablom and
      Loncomilla, Patricio and
      Javier Ruiz-del Solar",
    journal = "RoboCup@ Home",
    month = aug,
    year = "2017",
    url = {https://github.com/dcampanini/robocup_uchile},
    abstract = "The UChile HomeBreakers team is an effort of the Department of Electrical Engineering of the Universidad de Chile. The team has participated in the RoboCup@ Home league since 2007, and its social robot Bender obtained the@ Home Innovation Award in 2007 and 2008. As a team with strong expertise in robot vision, object recognition, and human-robot interaction, we believe that we can provide interesting features to the league. This year our main research focus is object recognition and its manipulation, because one of the principal abilities of a service robot is the interaction with objects. For this reason the team incorporated a new manipulation system, using the ROS package MoveIT!, and carried out a comparison among object recognition methods. Another important improvement in our social robot is a new face that allows it to more easily display emotions. Additionally, a long-term memory to store non-redundant information about people and objects with which the robot has interacted, as well as places and dates where sessions have been carried out, was implemented.",
    selected={true}
}